name: Run Saramin Crawler

on:
  workflow_dispatch:      # Actions íƒ­ì—ì„œ ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥
  schedule:
    - cron: "0 0 * * *"   # ë§¤ì¼ í•œêµ­ì‹œê°„ ì˜¤ì „ 9ì‹œ (UTC+0 ê¸°ì¤€ 00ì‹œ)

jobs:
  run:
    runs-on: ubuntu-latest
    permissions:
      contents: write    # docs í´ë”ì— HTML ì €ì¥ í›„ ì»¤ë°‹í•˜ê¸° ìœ„í•¨

    env:
      EMAIL_SENDER: ${{ secrets.EMAIL_SENDER }}
      EMAIL_RECEIVER: ${{ secrets.EMAIL_RECEIVER }}
      EMAIL_APP_PASSWORD: ${{ secrets.EMAIL_APP_PASSWORD }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0   # ì „ì²´ ê¸°ë¡ ê°€ì ¸ì˜¤ê¸° (rebaseë¥¼ ìœ„í•´ í•„ìš”)

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install requests beautifulsoup4 pandas google-auth google-auth-oauthlib google-api-python-client

      - name: Run Saramin Crawler
        run: python test.py   # âš  ì—¬ê¸°ì„œ íŒŒì¼ëª… í™•ì¸í•´ì„œ ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”

      - name: Commit and Push HTML & CSV
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # âœ… ì›ê²© ë³€ê²½ì‚¬í•­ì„ rebase ë°©ì‹ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
          git pull --rebase origin main || true

          # docs/*.html(HTML)ê³¼ *.csv(CSV)ë¥¼ ìŠ¤í…Œì´ì§•
          git add docs/*.html *.csv || true

          if git diff --cached --quiet; then
            echo "âœ… ë³€ê²½ëœ íŒŒì¼ ì—†ìŒ. ì»¤ë°‹ ìƒëµ."
          else
            git commit -m "ğŸ”„ Auto update saramin_results_latest.html & CSV ($(date -u +'%Y-%m-%dT%H:%M:%SZ'))"
            git push origin main
            echo "âœ… ë³€ê²½ì‚¬í•­ì´ ì„±ê³µì ìœ¼ë¡œ ì»¤ë°‹ ë° í‘¸ì‹œë˜ì—ˆìŠµë‹ˆë‹¤."
          fi
