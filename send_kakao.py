# -*- coding: utf-8 -*-
import os, json, re, requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from datetime import datetime, timedelta, timezone

# ====== ì„¤ì • ======
KST = timezone(timedelta(hours=9))
REST_API_KEY  = os.getenv("KAKAO_REST_API_KEY")
REFRESH_TOKEN = os.getenv("KAKAO_REFRESH_TOKEN")
PAGES_URL     = os.getenv("PAGES_URL", "https://pkpjs.github.io/test/saramin_results_latest.html")
HTML_PATH     = "docs/saramin_results_latest.html"
SARAMIN_BASE  = "https://www.saramin.co.kr"

# IT/ë³´ì•ˆ í•„í„° í‚¤ì›Œë“œ (ì œëª©/ì§ë¬´/íšŒì‚¬/ìœ„ì¹˜ì— í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ í†µê³¼)
IT_SECURITY_KEYWORDS = ["ë³´ì•ˆ", "ì‹œìŠ¤í…œ", "ë„¤íŠ¸ì›Œí¬", "ì •ë³´", "ë°±ì—”ë“œ", "ì„œë²„", "IT"]

# ë§ˆê°ì¼ ì„ë°• ì„ê³„ (KST ê¸°ì¤€ Nì¼ ì´ë‚´ë©´ ì„ë°• í‘œì‹œ)
IMMINENT_DAYS = 7

# ====== ê³µí†µ í•¨ìˆ˜ ======
def refresh_access_token() -> str:
    url = "https://kauth.kakao.com/oauth/token"
    data = {
        "grant_type": "refresh_token",
        "client_id": REST_API_KEY,
        "refresh_token": REFRESH_TOKEN,
    }
    r = requests.post(url, data=data, timeout=20)
    r.raise_for_status()
    js = r.json()
    if "access_token" not in js:
        raise RuntimeError(f"í† í° ê°±ì‹  ì‹¤íŒ¨: {js}")
    return js["access_token"]

def load_html_text() -> str:
    # ë¡œì»¬ ìš°ì„ , ì—†ìœ¼ë©´ Pagesì—ì„œ
    try:
        with open(HTML_PATH, "r", encoding="utf-8", errors="ignore") as f:
            return f.read()
    except FileNotFoundError:
        r = requests.get(PAGES_URL, timeout=20)
        r.raise_for_status()
        return r.text

def parse_deadline(text: str) -> datetime | None:
    """
    ì‚¬ëŒì¸ ë§ˆê° í‘œê¸° ì˜ˆ: "~ 11/14(ê¸ˆ)", "~11.02", "~ 11-04", "ì±„ìš©ì‹œ ë§ˆê°", "ìƒì‹œ"
    - ì›”/ì¼ë§Œ ìˆìœ¼ë©´ ì˜¬í•´ ê¸°ì¤€ìœ¼ë¡œ í•´ì„
    - ë‚ ì§œê°€ ì´ë¯¸ ì§€ë‚˜ë„ 'ì˜¬í•´' ê¸°ì¤€ ìœ ì§€ (ë‹¨, ë„ˆë¬´ ê³¼ê±°ë©´ +1ë…„ ë³´ì •)
    """
    if not text:
        return None
    t = text.strip()
    if any(k in t for k in ["ìƒì‹œ", "ì±„ìš©ì‹œ", "ìˆ˜ì‹œ"]):
        return None  # ì‚¬ì‹¤ìƒ ë¬´ê¸°í•œ â†’ ì •ë ¬ì—ì„œ ë’¤ë¡œ ë°€ë¦¼

    # "~ 11/14(ê¸ˆ)" ë“±ì—ì„œ ì›”/ì¼ ì¶”ì¶œ
    m = re.search(r'(\d{1,2})\s*[./-]\s*(\d{1,2})', t)
    if not m:
        # "11ì›” 14ì¼" íŒ¨í„´
        m = re.search(r'(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼', t)
    if not m:
        return None

    month = int(m.group(1))
    day   = int(m.group(2))
    now = datetime.now(KST)
    year = now.year

    try_date = datetime(year, month, day, tzinfo=KST)
    # ë„ˆë¬´ ê³¼ê±°ì²˜ëŸ¼ ë³´ì´ë©´ +1ë…„ (ì—°ë§/ì—°ì´ˆ ê±¸ë¦¼ ë°©ì§€)
    if try_date < now - timedelta(days=180):
        try_date = datetime(year + 1, month, day, tzinfo=KST)
    return try_date

def is_it_security(hit_fields: list[str]) -> bool:
    bag = " ".join([x for x in hit_fields if x]).lower()
    return any(k.lower() in bag for k in IT_SECURITY_KEYWORDS)

# ====== íŒŒì‹± ======
def extract_items():
    """
    í‘œ ì»¬ëŸ¼ ì˜ˆ:
    ë§í¬(ì œëª©) | íšŒì‚¬ | ìœ„ì¹˜ | ê²½ë ¥ | í•™ë ¥ | ë§ˆê°ì¼ | ë°”ë¡œê°€ê¸°
    """
    html = load_html_text()
    soup = BeautifulSoup(html, "lxml")
    table = soup.find("table")
    if not table:
        return [], 0

    headers = [th.get_text(strip=True) for th in table.select("thead tr th")]
    if not headers:
        first = table.find("tr")
        if first:
            headers = [th.get_text(strip=True) for th in first.find_all(["th", "td"])]

    rows = table.select("tbody tr") or table.find_all("tr")[1:]
    total = len(rows)

    def idx(*names):
        for n in names:
            if n in headers:
                return headers.index(n)
        return None

    i_link   = idx("ë§í¬", "ì œëª©")
    i_company= idx("íšŒì‚¬", "company")
    i_loc    = idx("ìœ„ì¹˜", "location")
    i_job    = idx("ì§ë¬´", "job")
    i_dead   = idx("ë§ˆê°ì¼", "ë§ˆê°", "deadline")
    i_direct = idx("ë°”ë¡œê°€ê¸°")

    items = []
    for tr in rows:
        tds = tr.find_all("td")
        if not tds:
            continue

        title, url = "", ""
        if i_link is not None and i_link < len(tds):
            a = tds[i_link].find("a", href=True)
            if a:
                title = a.get_text(strip=True)
                href = a["href"].strip()
                url = href if href.startswith("http") else urljoin(SARAMIN_BASE, href)
            else:
                title = tds[i_link].get_text(strip=True)

        # ë³´ì¡° URL: 'ë°”ë¡œê°€ê¸°' ì¹¼ëŸ¼
        if not url and i_direct is not None and i_direct < len(tds):
            a2 = tds[i_direct].find("a", href=True)
            if a2:
                href2 = a2["href"].strip()
                url = href2 if href2.startswith("http") else urljoin(SARAMIN_BASE, href2)

        company = tds[i_company].get_text(strip=True) if i_company is not None and i_company < len(tds) else ""
        loc     = tds[i_loc].get_text(strip=True)     if i_loc     is not None and i_loc     < len(tds) else ""
        job     = tds[i_job].get_text(strip=True)     if i_job     is not None and i_job     < len(tds) else ""
        deadraw = tds[i_dead].get_text(strip=True)    if i_dead    is not None and i_dead    < len(tds) else ""

        deadline = parse_deadline(deadraw)
        items.append({
            "title": title or "(ì œëª© ì—†ìŒ)",
            "company": company,
            "location": loc,
            "job": job,
            "deadline": deadline,   # datetime | None
            "deadline_text": deadraw,
            "url": url or PAGES_URL
        })
    return items, total

# ====== ì •ë ¬/í•„í„°/ìƒìœ„ N ======
def select_top10(items):
    # 1) IT/ë³´ì•ˆ í‚¤ì›Œë“œ í•„í„°
    filtered = [x for x in items if is_it_security([x["title"], x["company"], x["location"], x["job"]])]

    # 2) ë§ˆê°ì¼ ì„ë°•ìˆœ ì •ë ¬ (Noneì€ ë’¤ë¡œ)
    def sort_key(x):
        return (x["deadline"] is None, x["deadline"] or datetime.max.replace(tzinfo=KST))
    filtered.sort(key=sort_key)

    # 3) ë¶€ì¡±í•˜ë©´ ì¼ë°˜ ê³µê³ ë¡œ ë³´ì¶© (ê°™ì€ ì •ë ¬)
    if len(filtered) < 10:
        others = [x for x in items if x not in filtered]
        others.sort(key=sort_key)
        filtered.extend(others)

    # 4) TOP10
    return filtered[:10]

# ====== ì „ì†¡ ======
def send_text_header(access_token: str, total_count: int):
    today = datetime.now(KST).strftime("%Y-%m-%d")
    text = f"ğŸ“… {today} ì±„ìš©ê³µê³  TOP 10 (ë³´ì•ˆ/IT ì§êµ°)\nì´ {total_count}ê±´ì—ì„œ ì„ ë³„Â·ì •ë ¬í–ˆìŠµë‹ˆë‹¤."
    url = "https://kapi.kakao.com/v2/api/talk/memo/default/send"
    template_object = {
        "object_type": "text",
        "text": text,
        "link": {"web_url": PAGES_URL, "mobile_web_url": PAGES_URL},
        "button_title": "ì „ì²´ ê³µê³  ë³´ê¸°"
    }
    headers = {"Authorization": f"Bearer {access_token}"}
    data = {"template_object": json.dumps(template_object, ensure_ascii=False)}
    r = requests.post(url, headers=headers, data=data, timeout=20)
    r.raise_for_status()
    js = r.json()
    if js.get("result_code") != 0:
        raise RuntimeError(f"í—¤ë” ì „ì†¡ ì‹¤íŒ¨: {js}")

def send_feed_card(access_token: str, rank: int, item: dict):
    # ë§ˆê°ì¼ í…ìŠ¤íŠ¸ êµ¬ì„±
    now = datetime.now(KST)
    imminent = (item["deadline"] and (item["deadline"].date() - now.date()).days <= IMMINENT_DAYS)
    dead_txt = item["deadline_text"] or ("ìƒì‹œ" if item["deadline"] is None else "")
    prefix = "ğŸ”¥ " if imminent else ""
    desc_lines = []
    if item["company"]:
        desc_lines.append(item["company"])
    if item["location"] or item["job"]:
        desc_lines.append(" | ".join([t for t in [item["location"], item["job"]] if t]))
    if dead_txt:
        desc_lines.append(f"ë§ˆê°ì¼: {dead_txt}")
    desc = "\n".join(desc_lines)

    template_object = {
        "object_type": "feed",
        "content": {
            "title": f"{prefix}{rank}ìœ„ | {item['title']}",
            "description": desc,
            "link": {"web_url": item["url"], "mobile_web_url": item["url"]},
        },
        "buttons": [
            {"title": "ê³µê³  ë°”ë¡œê°€ê¸° ğŸ”—", "link": {"web_url": item["url"], "mobile_web_url": item["url"]}}
        ]
    }
    url = "https://kapi.kakao.com/v2/api/talk/memo/default/send"
    headers = {"Authorization": f"Bearer {access_token}"}
    data = {"template_object": json.dumps(template_object, ensure_ascii=False)}
    r = requests.post(url, headers=headers, data=data, timeout=20)
    r.raise_for_status()
    js = r.json()
    if js.get("result_code") != 0:
        raise RuntimeError(f"{rank}ìœ„ ì „ì†¡ ì‹¤íŒ¨: {js}")

def send_full_button(access_token: str):
    template_object = {
        "object_type": "feed",
        "content": {
            "title": "ì „ì²´ ê³µê³  í•œ ë²ˆì— ë³´ê¸°",
            "description": "GitHub Pagesì—ì„œ ìµœì‹  ì „ì²´ ëª©ë¡ í™•ì¸",
            "link": {"web_url": PAGES_URL, "mobile_web_url": PAGES_URL},
        },
        "buttons": [
            {"title": "ì „ì²´ë³´ê¸° ğŸ”—", "link": {"web_url": PAGES_URL, "mobile_web_url": PAGES_URL}}
        ]
    }
    url = "https://kapi.kakao.com/v2/api/talk/memo/default/send"
    headers = {"Authorization": f"Bearer {access_token}"}
    data = {"template_object": json.dumps(template_object, ensure_ascii=False)}
    r = requests.post(url, headers=headers, data=data, timeout=20)
    r.raise_for_status()

# ====== ë©”ì¸ ======
def main():
    access_token = refresh_access_token()
    items_all, total = extract_items()
    if not items_all:
        print("âŒ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨(í‘œ ë¯¸ë°œê²¬)")
        return

    top10 = select_top10(items_all)

    # í—¤ë”(ë‚ ì§œ/ìš”ì•½)
    send_text_header(access_token, total_count=total)

    # TOP10 ê°œë³„ ì¹´ë“œ
    for i, it in enumerate(top10, start=1):
        send_feed_card(access_token, i, it)

    # ì „ì²´ë³´ê¸° ë²„íŠ¼
    send_full_button(access_token)

    print(f"âœ… ì „ì†¡ ì™„ë£Œ: ì´ {len(top10)}ê°œ (ì „ì²´ ì›ë³¸ {total}ê±´)")

if __name__ == "__main__":
    main()
